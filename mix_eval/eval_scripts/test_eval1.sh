# python -m mix_eval.evaluate \
#     --model_name claude_3_haiku \
#     --benchmark mixeval_hard \
#     --version 2024-06-01 \
#     --batch_size 20 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100

# python -m mix_eval.evaluate \
#     --model_name mistral_small \
#     --benchmark mixeval_hard \
#     --version 2024-06-01 \
#     --batch_size 20 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100


# python -m mix_eval.evaluate \
#     --model_name reka_edge \
#     --benchmark mixeval_hard \
#     --version 2024-06-01 \
#     --batch_size 20 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100


# python -m mix_eval.evaluate \
#     --model_name claude_3_haiku \
#     --benchmark mixeval \
#     --version 2024-06-01 \
#     --batch_size 20 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100

# python -m mix_eval.evaluate \
#     --model_name mistral_small \
#     --benchmark mixeval \
#     --version 2024-06-01 \
#     --batch_size 20 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100


# python -m mix_eval.evaluate \
#     --model_name reka_edge \
#     --benchmark mixeval \
#     --version 2024-06-01 \
#     --batch_size 20 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100

python -m mix_eval.evaluate \
    --model_name gpt_4o_mini \
    --benchmark mixeval_hard \
    --version 2024-06-01 \
    --batch_size 100 \
    --output_dir mix_eval/data/model_responses/ \
    --api_parallel_num 100


python -m mix_eval.evaluate \
    --model_name gpt_4o_mini \
    --benchmark mixeval \
    --version 2024-06-01 \
    --batch_size 100 \
    --output_dir mix_eval/data/model_responses/ \
    --api_parallel_num 100


# python -m mix_eval.evaluate \
#     --model_name mistral_large_2 \
#     --benchmark mixeval_hard \
#     --version 2024-06-01 \
#     --batch_size 20 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100

# python -m mix_eval.evaluate \
#     --model_name mistral_nemo \
#     --benchmark mixeval_hard \
#     --version 2024-06-01 \
#     --batch_size 20 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100

# python -m mix_eval.evaluate \
#     --model_name mistral_large_2 \
#     --benchmark mixeval \
#     --version 2024-06-01 \
#     --batch_size 20 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100

# python -m mix_eval.evaluate \
#     --model_name mistral_nemo \
#     --benchmark mixeval \
#     --version 2024-06-01 \
#     --batch_size 20 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100

# python -m mix_eval.evaluate \
#     --model_name openai_o1 \
#     --benchmark mixeval_hard \
#     --version 2024-06-01 \
#     --batch_size 5 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100

# python -m mix_eval.evaluate \
#     --model_name openai_o1 \
#     --benchmark mixeval \
#     --version 2024-06-01 \
#     --batch_size 5 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100

# python -m mix_eval.evaluate \
#     --model_name openai_o1_mini \
#     --benchmark mixeval_hard \
#     --version 2024-06-01 \
#     --batch_size 5 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100

# python -m mix_eval.evaluate \
#     --model_name openai_o1_mini \
#     --benchmark mixeval \
#     --version 2024-06-01 \
#     --batch_size 5 \
#     --output_dir mix_eval/data/model_responses/ \
#     --api_parallel_num 100